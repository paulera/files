#!/usr/bin/env python3
# AI-MADE
# https://chatgpt.com/share/68652076-c23c-800f-9cc5-cfff4a7a1616
"""
Simple CLI tool to run JQL queries against a Jira instance and display results in an ASCII table with optional field wrapping/truncation,
or raw output for scripting, or list and cache available JQL fields for alias mapping.
Cached alias mappings are stored in ~/.jql_config.json.

Usage:
  jql [-f fields] [-r|--raw] [-s SEP] [-n LIMIT] [-T TABLEFMT] [--list-fields [all|jira|custom|update]] <JQL query>

Fields syntax:
  Specify fields as comma-separated names, with optional wrapping (parentheses) or truncation (curly braces):
    summary(40),status,priority{10},cf[10162]
  - summary(40) wraps at 40 chars
  - priority{10} truncates at 10 chars
  - status, cf[10162] use alias mapping

Environment variables:
  JIRA_API_TOKEN  - your Jira API token
  JIRA_URL        - the base URL of your Jira instance (e.g. https://your-domain.atlassian.net)
  JIRA_USER       - your Jira user/email

Options:
  -f, --fields      Fields list, e.g. issuekey,summary(50),status,priority{10},cf[10162]
  -r, --raw         Raw output mode
  -s SEP, --sep SEP Field separator for raw mode (default: "|")
  -n LIMIT, --limit LIMIT
                     Maximum number of issues to return (default: 100; -1 for all)
  -T TABLEFMT, --tablefmt TABLEFMT
                     Table format for visual mode (default: "simple_grid")
  --list-fields [all|jira|custom|update]
                     List fields (all/jira/custom) or update cache
  -h, --help        Show this help message and exit
"""
import os
import sys
import json
import argparse
import requests
import re
import textwrap
from requests.auth import HTTPBasicAuth
from tabulate import tabulate

CONFIG_PATH = os.path.expanduser('~/.jql_config.json')


def fetch_issues(api_search, auth, params, limit):
    issues = []
    start_at = 0
    page_size = 100 if limit < 0 else min(limit, 100)
    while True:
        params.update({'startAt': start_at, 'maxResults': page_size})
        resp = requests.get(api_search, auth=auth, params=params)
        if resp.status_code != 200:
            sys.stderr.write(f"Error: Jira API returned {resp.status_code}: {resp.text}\n")
            sys.exit(1)
        data = resp.json()
        batch = data.get('issues', [])
        if not batch:
            break
        issues.extend(batch)
        if limit > 0 and len(issues) >= limit:
            issues = issues[:limit]
            break
        if len(batch) < page_size:
            break
        start_at += page_size
    return issues


def extract_text_from_doc(node):
    text = ''
    if isinstance(node, dict):
        if 'text' in node:
            return node['text']
        for val in node.get('content', []) or []:
            text += extract_text_from_doc(val)
    elif isinstance(node, list):
        for item in node:
            text += extract_text_from_doc(item)
    return text


def fetch_fields(api_endpoint, auth):
    resp = requests.get(f"{api_endpoint.rstrip('/')}/rest/api/3/field", auth=auth)
    if resp.status_code != 200:
        sys.stderr.write(f"Error fetching fields: {resp.status_code}: {resp.text}\n")
        sys.exit(1)
    return resp.json()


def build_mappings(fields):
    alias_map = {}
    id_map = {}
    for f in fields:
        fid = f['id']
        name = f['name']
        id_map[fid] = name
        alias_map[name] = fid
        for c in f.get('clauseNames', []) or []:
            alias_map[c] = fid
        if fid.startswith('customfield_'):
            num = fid.split('_', 1)[1]
            alias_map[f'cf[{num}]'] = fid
    return alias_map, id_map


def list_fields(api_endpoint, auth, category):
    fields = fetch_fields(api_endpoint, auth)
    if category == 'jira':
        fields = [f for f in fields if not f['id'].startswith('customfield_')]
    elif category == 'custom':
        fields = [f for f in fields if f['id'].startswith('customfield_')]
    fields.sort(key=lambda f: f['name'].lower())
    for f in fields:
        fid = f['id']
        name = f['name']
        if fid.startswith('customfield_'):
            num = fid.split('_', 1)[1]
            fid = f'cf[{num}]'
        print(f"{name}:{fid}")
    sys.exit(0)


def update_cache(api_endpoint, auth):
    fields = fetch_fields(api_endpoint, auth)
    alias_map, id_map = build_mappings(fields)
    with open(CONFIG_PATH, 'w') as fp:
        json.dump({'alias_map': alias_map, 'id_map': id_map}, fp)
    print(f"Updated cache: {len(alias_map)} entries written to {CONFIG_PATH}")
    sys.exit(0)


def load_cache():
    if os.path.exists(CONFIG_PATH):
        try:
            cfg = json.load(open(CONFIG_PATH))
            return cfg.get('alias_map', {}), cfg.get('id_map', {})
        except Exception:
            return {}, {}
    return {}, {}


def main():
    jira_url = os.getenv('JIRA_URL')
    api_token = os.getenv('JIRA_API_TOKEN')
    user = os.getenv('JIRA_USER')
    if not jira_url or not api_token or not user:
        sys.stderr.write("Error: JIRA_URL, JIRA_API_TOKEN, and JIRA_USER must be set.\n")
        sys.exit(1)

    parser = argparse.ArgumentParser(
        prog='jql',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description='Run JQL queries or manage field aliases (cached in ~/.jql_config.json).',
        epilog=__doc__
    )
    parser.add_argument('-f', '--fields', default='issuekey,type,priority,status,summary',
        help='Fields list, e.g. issuekey,summary(50),status,priority{10},cf[10162]')
    parser.add_argument('-r', '--raw', action='store_true', help='Raw output mode')
    parser.add_argument('-s', '--sep', default='|', help='Raw mode separator')
    parser.add_argument('-n', '--limit', type=int, default=100,
        help='Max issues (default 100; -1 for all)')
    parser.add_argument('-T', '--tablefmt', default='simple_grid',
        help='Table format for visual mode')
    parser.add_argument('--list-fields', nargs='?', const='all',
        choices=['all', 'jira', 'custom', 'update'],
        help='List fields (all/jira/custom) or update cache and exit')
    parser.add_argument('jql', nargs='*', help='JQL query')
    args = parser.parse_args()

    auth = HTTPBasicAuth(user, api_token)
    api_endpoint = jira_url.rstrip('/')

    if args.list_fields:
        if args.list_fields == 'update':
            update_cache(api_endpoint, auth)
        else:
            list_fields(api_endpoint, auth, args.list_fields)

    alias_map, id_map = load_cache()
    if not alias_map or not id_map:
        print("Cache missing or empty, updating...")
        update_cache(api_endpoint, auth)

    specs = []
    for spec in args.fields.split(','):
        raw_spec = spec.strip()
        wrap = None
        trunc = None
        m_wrap = re.match(r'^(.+?)\((\d+)\)$', raw_spec)
        m_trunc = re.match(r'^(.+?)\{(\d+)\}$', raw_spec)
        if m_wrap:
            alias = m_wrap.group(1)
            wrap = int(m_wrap.group(2))
        elif m_trunc:
            alias = m_trunc.group(1)
            trunc = int(m_trunc.group(2))
        else:
            alias = raw_spec
        real = alias_map.get(alias, alias)
        display = alias if alias == 'issuekey' else id_map.get(real, alias)
        specs.append((real, wrap, trunc, display))

    field_keys = [real for (real, _, _, _) in specs]
    if not args.jql:
        parser.error('JQL query required')

    jql_query = ' '.join(args.jql)
    params = {'jql': jql_query, 'fields': ','.join(field_keys)}
    issues = fetch_issues(f"{api_endpoint}/rest/api/3/search", auth, params, args.limit)
    if not issues:
        print("No issues found.")
        return

    raw_rows = []
    vis_rows = []
    for issue in issues:
        row_raw = []
        row_vis = []
        data = issue.get('fields', {})
        for real, wrap, trunc, display in specs:
            if real == 'issuekey':
                val = issue.get('key', '')
            else:
                raw_val = data.get(real, '')
                if isinstance(raw_val, dict):
                    if raw_val.get('type') == 'doc':
                        val = extract_text_from_doc(raw_val)
                    elif 'value' in raw_val:
                        val = raw_val['value']
                    elif 'name' in raw_val:
                        val = raw_val['name']
                    else:
                        val = str(raw_val)
                elif isinstance(raw_val, list):
                    items = []
                    for it in raw_val:
                        if isinstance(it, dict):
                            if it.get('type') == 'doc':
                                items.append(extract_text_from_doc(it))
                            elif 'value' in it:
                                items.append(str(it['value']))
                            elif 'name' in it:
                                items.append(str(it['name']))
                            else:
                                items.append(str(it))
                        else:
                            items.append(str(it))
                    val = ','.join(items)
                else:
                    val = str(raw_val)
            val = val.strip()
            row_raw.append(val)
            if wrap is not None:
                row_vis.append(textwrap.fill(val, width=wrap))
            elif trunc is not None:
                row_vis.append(val[:trunc].strip())
            else:
                row_vis.append(val)
        raw_rows.append(row_raw)
        vis_rows.append(row_vis)

    if args.raw:
        for row in raw_rows:
            print(args.sep.join(row))
    else:
        print(f"\n\033[1;33m{jql_query}\033[0m")
        print(f"\033[1;37m{len(issues)} rows\033[0m\n")
        headers = [f"\033[1;37m{display}\033[0m" for (_, _, _, display) in specs]
        print(tabulate(vis_rows, headers=headers, tablefmt=args.tablefmt))

if __name__ == '__main__':
    main()

