#!/usr/bin/env python3
# 
# Built with AI assistance. Started from https://chatgpt.com/share/68652076-c23c-800f-9cc5-cfff4a7a1616
# then continued with copilot and manual edits.
#
# ---------------------------------------------
# never remove these instructions:
# * You must use the "enhanced search" endpoint https://developer.atlassian.com/cloud/jira/platform/rest/v3/api-group-issue-search/#api-rest-api-3-search-jql-get
# * This is your test: `jql "Project = SPO and created > 2025-10-01 and created < 2026-01-01" -c` must be equal to 182
# ---------------------------------------------
"""
CLI tool to run JQL queries against Jira, with table or raw output.

Features:
  • Wrap/truncate columns
  • Auto-cached field → API name map
  • Manual field aliases
  • Column header renaming
  • Debug verbosity flags (--debug)
  • Query/row-count display flags

Config dir ~/.jql-config/:
  fields-map-cache.json   ← auto field_name→id
  fields-aliases.json     ← user alias→field id
  columns-rename.json     ← user field→header rename

Usage:
  jql [-f fields] [-r] [-s SEP] [-n LIMIT] [-T TF]
      [-q] [-c] [-d DEBUG_FLAGS]
      [--list-fields [all|jira|custom|update]] <JQL>

Jira OAuth 2.0 scopes required:
    Classic:    read:jira-work
    Granular:   read:issue-details:jira
                read:audit-log:jira
                read:avatar:jira
                read:field-configuration:jira
                read:issue-meta:jira
                read:field.default-value:jira
                read:field.option:jira
                read:field:jira
                read:group:jira

Debug flags (comma-separated):
  keep-json-objects       show full JSON for complex fields
"""
import os
import sys
import json
import argparse
import requests
import re
import textwrap
from requests.auth import HTTPBasicAuth
from tabulate import tabulate
from colorama import Fore, Back, Style, init as colorama_init  # added

# Constants
CONFIG_DIR = os.path.expanduser("~/.jql-config")
CACHE_FILE = os.path.join(CONFIG_DIR, "fields-map-cache.json")
ALIASES_FILE = os.path.join(CONFIG_DIR, "fields-aliases.json")
RENAME_FILE = os.path.join(CONFIG_DIR, "columns-rename.json")
CF_RE = re.compile(r'^cf\[(\d+)\]$')

# --- Color support ----------------------------------------------------------

def get_color(field, value):
    """
    Return color codes for field-based coloring.
    """
    fg = ''
    bg = ''

    if field == 'status':
        if value == 'done':
            fg = Style.BRIGHT + Fore.LIGHTWHITE_EX
            bg = Back.GREEN
        elif value == 'discarded':
            fg = Fore.GREEN
        elif value in ['backlog','to do']:
            fg = Style.BRIGHT + Fore.WHITE
            bg = Back.LIGHTBLACK_EX
        elif value in ['in progress', 'review', 'qa', 'ready to deploy']:
            fg = Style.BRIGHT + Fore.WHITE
            bg = Back.BLUE
        elif value in ['blocked']:
            fg = Fore.BLACK
            bg = Back.LIGHTYELLOW_EX
    elif field == 'priority':
        if value == 'highest':
            fg = Style.BRIGHT + Fore.LIGHTRED_EX
        elif value == 'high':
            fg = Fore.LIGHTYELLOW_EX
        elif value == 'medium':
            fg = Fore.WHITE
        elif value == 'low':
            fg = Fore.LIGHTBLUE_EX
        elif value == 'lowest':
            fg = Style.DIM + Fore.LIGHTBLUE_EX
    elif field == 'issue type':
        if value == 'task':
            fg = Style.BRIGHT + Fore.LIGHTBLUE_EX
        elif value == 'story':
            fg = Style.BRIGHT + Fore.LIGHTGREEN_EX
        elif value == 'bug':
            fg = Style.BRIGHT + Fore.LIGHTRED_EX
        elif value == 'epic':
            fg = Style.BRIGHT + Fore.LIGHTMAGENTA_EX

    return fg, bg

def colorize(field, val):
    """
    Wrap a value with color codes.
    """
    fg, bg = get_color(field, val.lower())
    if fg or bg:
        return f"{bg}{fg}{val}{Style.RESET_ALL}"
    return val

# Helpers

def ensure_config_dir():
    os.makedirs(CONFIG_DIR, exist_ok=True)


def load_json(path):
    try:
        with open(path) as f:
            return json.load(f)
    except Exception:
        return {}


def save_json(path, obj):
    try:
        with open(path, 'w') as f:
            json.dump(obj, f, indent=2)
    except Exception:
        pass


def fetch_issues(url, auth, params, limit):
    issues = []
    page = 100 if limit < 0 else min(limit, 100)
    next_page_token = None
    
    while True:
        current_params = params.copy()
        current_params['maxResults'] = page
        if next_page_token:
            current_params['nextPageToken'] = next_page_token
        
        r = requests.get(url, auth=auth, params=current_params)
        if r.status_code != 200:
            sys.exit(f"Error: {r.status_code} {r.text}")
        
        data = r.json()
        batch = data.get('issues', [])
        if not batch:
            break
        
        issues.extend(batch)
        
        if limit >= 0 and len(issues) >= limit:
            issues = issues[:limit]
            break
        
        # Check if there are more results using isLast
        if data.get('isLast', True):
            break
        
        # Get next page token for pagination
        next_page_token = data.get('nextPageToken')
        if not next_page_token:
            break
        
        # Adjust page size if we're close to the limit
        if limit >= 0:
            remaining = limit - len(issues)
            page = min(page, remaining)
    
    return issues


def extract_text(node):
    if isinstance(node, dict):
        if node.get('type') == 'text':
            return node.get('text', '')
        return ''.join(extract_text(c) for c in node.get('content', []))
    if isinstance(node, list):
        return ''.join(extract_text(i) for i in node)
    return ''


def fetch_id_map(api, auth):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            return {}
        id_map = {}
        for f in r.json():
            id_map[f['id']] = f['name']
        return id_map
    except Exception:
        return {}

# Cache update

def update_field_cache(api, auth):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            return
        field_map = {}
        for f in r.json():
            fid, name = f['id'], f['name']
            field_map[name] = fid
            for clause in f.get('clauseNames', []) or []:
                field_map[clause] = fid
        field_map = {k: v for k, v in field_map.items() if not CF_RE.match(k)}
        ensure_config_dir()
        save_json(CACHE_FILE, field_map)
    except Exception:
        pass

# List fields

def list_fields(api, auth, category):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            sys.exit("Error listing fields")
        fields = r.json()
        if category == 'jira':
            fields = [f for f in fields if not f['id'].startswith('customfield_')]
        elif category == 'custom':
            fields = [f for f in fields if f['id'].startswith('customfield_')]
        for f in sorted(fields, key=lambda x: x['name'].lower()):
            fid, name = f['id'], f['name']
            if fid.startswith('customfield_'):
                fid = f"cf[{fid.split('_',1)[1]}]"
            print(f"{name}:{fid}")
    except Exception:
        pass
    sys.exit(0)

# Load maps

def load_maps():
    field_map = load_json(CACHE_FILE) or {}
    alias_map = load_json(ALIASES_FILE) or {}
    col_rename = load_json(RENAME_FILE) or {}
    return field_map, alias_map, col_rename

# Main

def main():
    api = os.getenv('JIRA_URL', '').rstrip('/')
    auth = HTTPBasicAuth(os.getenv('JIRA_USER', ''), os.getenv('JIRA_API_TOKEN', ''))
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=__doc__
    )
    parser.add_argument(
        '-f', '--fields',
        default='key,issuetype(15),priority,status(15),summary(30),assignee(15)',
        help='Fields list (default: key,issuetype(15),priority,status(15),summary(30),assignee(15))'
    )
    parser.add_argument(
        '-r', '--raw',
        action='store_true',
        help='Raw output mode: values separated by SEP'
    )
    parser.add_argument(
        '-s', '--sep',
        default='|',
        help='Field separator for raw mode (default: "|")'
    )
    parser.add_argument(
        '-n', '--limit',
        type=int, default=1000,
        help='Max issues to fetch (default: 1000; -1 for all)'
    )
    parser.add_argument(
        '-T', '--tablefmt',
        default='simple_grid',
        help='Table format for visual mode (default: "simple_grid")'
    )
    parser.add_argument(
        '-q', '--show-query',
        action='store_true',
        help='Show JQL query above output'
    )
    parser.add_argument(
        '-c', '--show-rows-count',
        action='store_true',
        help='Show row count below output'
    )
    parser.add_argument(
        '--color',
        choices=['auto', 'always', 'never'],
        default='auto',
        help='When to use colors: auto (default), always, or never'
    )
    parser.add_argument(
        '-d', '--debug',
        help='Comma-separated debug flags (e.g. keep-json-objects)',
        default=''        
    )
    parser.add_argument(
        '--list-fields',
        nargs='?', const='all',
        choices=['all','jira','custom','update'],
        help='List fields or update cache'
    )
    parser.add_argument(
        'jql', nargs='*',
        help='The JQL query to execute'
    )
    args = parser.parse_args()

    debug_flags = [f.strip() for f in args.debug.split(',') if f.strip()]

    if args.list_fields:
        if args.list_fields == 'update':
            update_field_cache(api, auth)
        list_fields(api, auth, args.list_fields)

    if not args.jql:
        parser.error('JQL query required')

    field_map, alias_map, col_rename = load_maps()
    if not field_map:
        update_field_cache(api, auth)
        field_map, alias_map, col_rename = load_maps()

    id_map = fetch_id_map(api, auth)

    specs = []
    for it in args.fields.split(','):
        alias = it.strip()
        wrap = None
        trunc = None
        m1 = re.match(r'^(.+?)\((\d+)\)$', alias)
        m2 = re.match(r'^(.+?)\{(\d+)\}$', alias)
        if m1:
            alias, wrap = m1.group(1), int(m1.group(2))
        elif m2:
            alias, trunc = m2.group(1), int(m2.group(2))

        if alias in alias_map:
            real = alias_map[alias]
        else:
            mcf = CF_RE.match(alias)
            if mcf:
                real = f"customfield_{mcf.group(1)}"
            else:
                real = field_map.get(alias, alias)

        default_header = id_map.get(real, real)
        header = col_rename.get(default_header, default_header)

        specs.append((real, wrap, trunc, header))

    url = f"{api}/rest/api/3/search/jql"
    params = {'jql': ' '.join(args.jql), 'fields': ','.join(r for r,_,_,_ in specs)}
    issues = fetch_issues(url, auth, params, args.limit)

    rows_raw = []
    rows_vis = []
    
    # Determine if color should be used
    use_color = args.color == 'always' or (args.color == 'auto' and sys.stdout.isatty())
    
    for issue in issues:
        row_r = []
        row_v = []
        data = issue.get('fields', {})
        for real, wrap, trunc, _ in specs:
            if real in ['key','issuekey']:
                val = issue.get('key', '')
            else:
                x = data.get(real, '')
                if 'json-objects' in debug_flags:
                    val = json.dumps(x)
                else:
                    if isinstance(x, dict):
                        if 'displayName' in x:
                            val = x['displayName']
                        elif x.get('type') == 'doc':
                            val = extract_text(x)
                        else:
                            val = x.get('value', x.get('name', str(x)))
                    elif isinstance(x, list):
                        vals = []
                        for it in x:
                            if isinstance(it, dict):
                                if 'displayName' in it:
                                    vals.append(it['displayName'])
                                elif it.get('type') == 'doc':
                                    vals.append(extract_text(it))
                                else:
                                    vals.append(it.get('value', it.get('name', str(it))))
                            else:
                                vals.append(str(it))
                        val = ','.join(vals)
                    else:
                        val = str(x)
            val = val.strip()
            row_r.append(val)
            if wrap is not None:
                vis_val = textwrap.fill(val, width=wrap)
            elif trunc is not None:
                vis_val = val[:trunc].strip()
            else:
                vis_val = val
            
            # Colorize if enabled
            if use_color:
                vis_val = colorize(id_map.get(real, real).lower(), vis_val)
            
            row_v.append(vis_val)
        rows_raw.append(row_r)
        rows_vis.append(row_v)

    if args.raw:
        for r in rows_raw:
            print(args.sep.join(r))
    else:
        if args.show_query:
            if use_color:
                print(f"\n{Style.BRIGHT}{Fore.YELLOW}{' '.join(args.jql)}{Style.RESET_ALL}\n")
            else:
                print(f"\n{' '.join(args.jql)}\n")
        if use_color:
            headers = [f"{Style.BRIGHT}{Fore.WHITE}{h}{Style.RESET_ALL}" for _,_,_,h in specs]
        else:
            headers = [h for _,_,_,h in specs]
        print(tabulate(rows_vis, headers=headers, tablefmt=args.tablefmt))
        if args.show_rows_count:
            if use_color:
                print(f"\n{Style.BRIGHT}{Fore.WHITE}{len(issues)} rows{Style.RESET_ALL}\n")
            else:
                print(f"\n{len(issues)} rows\n")

if __name__ == '__main__':
    main()