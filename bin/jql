#!/usr/bin/env python3
# AI-MADE
# https://chatgpt.com/share/68652076-c23c-800f-9cc5-cfff4a7a1616
"""
CLI tool to run JQL queries against Jira, with table or raw output.

Features:
  • Wrap/truncate columns
  • Auto-cached field → API name map
  • Manual field aliases
  • Column header renaming
  • Debug verbosity flags (--debug)
  • Query/row-count display flags

Config dir ~/.jql-config/:
  fields-map-cache.json   ← auto field_name→id
  fields-aliases.json     ← user alias→field id
  columns-rename.json     ← user field→header rename

Usage:
  jql [-f fields] [-r] [-s SEP] [-n LIMIT] [-T TF]
      [-q] [-c] [-d DEBUG_FLAGS]
      [--list-fields [all|jira|custom|update]] <JQL>

Debug flags (comma-separated):
  keep-json-objects       show full JSON for complex fields
"""
import os
import sys
import json
import argparse
import requests
import re
import textwrap
from requests.auth import HTTPBasicAuth
from tabulate import tabulate

# Constants
CONFIG_DIR = os.path.expanduser("~/.jql-config")
CACHE_FILE = os.path.join(CONFIG_DIR, "fields-map-cache.json")
ALIASES_FILE = os.path.join(CONFIG_DIR, "fields-aliases.json")
RENAME_FILE = os.path.join(CONFIG_DIR, "columns-rename.json")
CF_RE = re.compile(r'^cf\[(\d+)\]$')

# Helpers

def ensure_config_dir():
    os.makedirs(CONFIG_DIR, exist_ok=True)


def load_json(path):
    try:
        with open(path) as f:
            return json.load(f)
    except Exception:
        return {}


def save_json(path, obj):
    try:
        with open(path, 'w') as f:
            json.dump(obj, f, indent=2)
    except Exception:
        pass


def fetch_issues(url, auth, params, limit):
    issues = []
    start = 0
    page = 100 if limit < 0 else min(limit, 100)
    while True:
        params.update({'startAt': start, 'maxResults': page})
        r = requests.get(url, auth=auth, params=params)
        if r.status_code != 200:
            sys.exit(f"Error: {r.status_code} {r.text}")
        batch = r.json().get('issues', [])
        if not batch:
            break
        issues.extend(batch)
        if limit >= 0 and len(issues) >= limit:
            issues = issues[:limit]
            break
        if len(batch) < page:
            break
        start += page
    return issues


def extract_text(node):
    if isinstance(node, dict):
        if node.get('type') == 'text':
            return node.get('text', '')
        return ''.join(extract_text(c) for c in node.get('content', []))
    if isinstance(node, list):
        return ''.join(extract_text(i) for i in node)
    return ''


def fetch_id_map(api, auth):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            return {}
        id_map = {}
        for f in r.json():
            id_map[f['id']] = f['name']
        return id_map
    except Exception:
        return {}

# Cache update

def update_field_cache(api, auth):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            return
        field_map = {}
        for f in r.json():
            fid, name = f['id'], f['name']
            field_map[name] = fid
            for clause in f.get('clauseNames', []) or []:
                field_map[clause] = fid
        field_map = {k: v for k, v in field_map.items() if not CF_RE.match(k)}
        ensure_config_dir()
        save_json(CACHE_FILE, field_map)
    except Exception:
        pass

# List fields

def list_fields(api, auth, category):
    try:
        r = requests.get(f"{api}/rest/api/3/field", auth=auth)
        if r.status_code != 200:
            sys.exit("Error listing fields")
        fields = r.json()
        if category == 'jira':
            fields = [f for f in fields if not f['id'].startswith('customfield_')]
        elif category == 'custom':
            fields = [f for f in fields if f['id'].startswith('customfield_')]
        for f in sorted(fields, key=lambda x: x['name'].lower()):
            fid, name = f['id'], f['name']
            if fid.startswith('customfield_'):
                fid = f"cf[{fid.split('_',1)[1]}]"
            print(f"{name}:{fid}")
    except Exception:
        pass
    sys.exit(0)

# Load maps

def load_maps():
    field_map = load_json(CACHE_FILE) or {}
    alias_map = load_json(ALIASES_FILE) or {}
    col_rename = load_json(RENAME_FILE) or {}
    return field_map, alias_map, col_rename

# Main

def main():
    api = os.getenv('JIRA_URL', '').rstrip('/')
    auth = HTTPBasicAuth(os.getenv('JIRA_USER', ''), os.getenv('JIRA_API_TOKEN', ''))
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=__doc__
    )
    parser.add_argument(
        '-f', '--fields',
        default='key,issuetype(15),priority,status(15),summary(30),assignee(15)',
        help='Fields list (default: key,issuetype(15),priority,status(15),summary(30),assignee(15))'
    )
    parser.add_argument(
        '-r', '--raw',
        action='store_true',
        help='Raw output mode: values separated by SEP'
    )
    parser.add_argument(
        '-s', '--sep',
        default='|',
        help='Field separator for raw mode (default: "|")'
    )
    parser.add_argument(
        '-n', '--limit',
        type=int, default=100,
        help='Max issues to fetch (default: 100; -1 for all)'
    )
    parser.add_argument(
        '-T', '--tablefmt',
        default='simple_grid',
        help='Table format for visual mode (default: "simple_grid")'
    )
    parser.add_argument(
        '-q', '--show-query',
        action='store_true',
        help='Show JQL query above output'
    )
    parser.add_argument(
        '-c', '--show-rows-count',
        action='store_true',
        help='Show row count below output'
    )
    parser.add_argument(
        '-d', '--debug',
        help='Comma-separated debug flags (e.g. keep-json-objects)',
        default=''        
    )
    parser.add_argument(
        '--list-fields',
        nargs='?', const='all',
        choices=['all','jira','custom','update'],
        help='List fields or update cache'
    )
    parser.add_argument(
        'jql', nargs='*',
        help='The JQL query to execute'
    )
    args = parser.parse_args()

    debug_flags = [f.strip() for f in args.debug.split(',') if f.strip()]

    if args.list_fields:
        if args.list_fields == 'update':
            update_field_cache(api, auth)
        list_fields(api, auth, args.list_fields)

    if not args.jql:
        parser.error('JQL query required')

    field_map, alias_map, col_rename = load_maps()
    if not field_map:
        update_field_cache(api, auth)
        field_map, alias_map, col_rename = load_maps()

    id_map = fetch_id_map(api, auth)

    specs = []
    for it in args.fields.split(','):
        alias = it.strip()
        wrap = None
        trunc = None
        m1 = re.match(r'^(.+?)\((\d+)\)$', alias)
        m2 = re.match(r'^(.+?)\{(\d+)\}$', alias)
        if m1:
            alias, wrap = m1.group(1), int(m1.group(2))
        elif m2:
            alias, trunc = m2.group(1), int(m2.group(2))

        if alias in alias_map:
            real = alias_map[alias]
        else:
            mcf = CF_RE.match(alias)
            if mcf:
                real = f"customfield_{mcf.group(1)}"
            else:
                real = field_map.get(alias, alias)

        default_header = id_map.get(real, real)
        header = col_rename.get(default_header, default_header)

        specs.append((real, wrap, trunc, header))

    url = f"{api}/rest/api/3/search"
    params = {'jql': ' '.join(args.jql), 'fields': ','.join(r for r,_,_,_ in specs)}
    issues = fetch_issues(url, auth, params, args.limit)

    rows_raw = []
    rows_vis = []
    for issue in issues:
        row_r = []
        row_v = []
        data = issue.get('fields', {})
        for real, wrap, trunc, _ in specs:
            if real in ['key','issuekey']:
                val = issue.get('key', '')
            else:
                x = data.get(real, '')
                if 'json-objects' in debug_flags:
                    val = json.dumps(x)
                else:
                    if isinstance(x, dict):
                        if 'displayName' in x:
                            val = x['displayName']
                        elif x.get('type') == 'doc':
                            val = extract_text(x)
                        else:
                            val = x.get('value', x.get('name', str(x)))
                    elif isinstance(x, list):
                        vals = []
                        for it in x:
                            if isinstance(it, dict):
                                if 'displayName' in it:
                                    vals.append(it['displayName'])
                                elif it.get('type') == 'doc':
                                    vals.append(extract_text(it))
                                else:
                                    vals.append(it.get('value', it.get('name', str(it))))
                            else:
                                vals.append(str(it))
                        val = ','.join(vals)
                    else:
                        val = str(x)
            val = val.strip()
            row_r.append(val)
            if wrap is not None:
                row_v.append(textwrap.fill(val, width=wrap))
            elif trunc is not None:
                row_v.append(val[:trunc].strip())
            else:
                row_v.append(val)
        rows_raw.append(row_r)
        rows_vis.append(row_v)

    if args.raw:
        for r in rows_raw:
            print(args.sep.join(r))
    else:
        if args.show_query:
            print(f"\n\033[1;33m{' '.join(args.jql)}\033[0m\n")
        headers = [f"\033[1;37m{h}\033[0m" for _,_,_,h in specs]
        print(tabulate(rows_vis, headers=headers, tablefmt=args.tablefmt))
        if args.show_rows_count:
            print(f"\n\033[1;37m{len(issues)} rows\033[0m\n")

if __name__ == '__main__':
    main()
